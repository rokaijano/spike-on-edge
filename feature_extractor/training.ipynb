{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "toxic-baker",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\sg\\lib\\site-packages\\tensorflow_addons\\utils\\ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.5.0 and strictly below 2.8.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.8.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from nnclr import *\n",
    "import tensorflow as tf \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import time \n",
    "import scipy\n",
    "import sklearn\n",
    "\n",
    "from waveform_data import WaveFormDataset\n",
    "tf.random.set_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc74070",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 32 \n",
    "train_min_snr = 5\n",
    "\n",
    "train_dataset = WaveFormDataset(\n",
    "    [\"..\\\\supervised\\\\data\\\\hybrid_static_siprobe_64C_600_S11\"\n",
    "     ,\"..\\\\supervised\\\\data\\\\REC_32C_600S_31\"\n",
    "    ], \n",
    "    batch_size=train_batch_size, \n",
    "    min_snr = train_min_snr,\n",
    "    augmentation = True\n",
    ")()\n",
    "\n",
    "train_dataset = dset.create_sg_dataset([\"..\\\\data\\\\hybrid_static_siprobe_64C_600_S11\",\"..\\\\data\\\\REC_32C_600S_31\"], noise1=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a76e668",
   "metadata": {},
   "outputs": [],
   "source": [
    "INITIAL_LR = 0.001\n",
    "DECAY_STEPS = 3000\n",
    "\n",
    "temperature = 0.1\n",
    "queue_size = 10000\n",
    "\n",
    "LR = tf.keras.experimental.CosineDecay(INITIAL_LR, DECAY_STEPS, 1e-1)\n",
    "\n",
    "\n",
    "#LR = 0.0001\n",
    "model = NNCLR(temperature=temperature, queue_size=queue_size)\n",
    "model.compile(\n",
    "    contrastive_optimizer=keras.optimizers.Adam(LR),\n",
    "    probe_optimizer=keras.optimizers.Adam(LR),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9f7779",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    train_dataset, \n",
    "    epochs=500\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9b158b",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_res = []\n",
    "\n",
    "target_samples = []\n",
    "\n",
    "it = iter(train_dataset)\n",
    "for i in range(10):\n",
    "    sample = next(it)\n",
    "    \n",
    "    result = model.encoder(sample[0])\n",
    "        \n",
    "    result = tf.reshape(result, [-1,width])\n",
    "    \n",
    "    target_samples.extend(tf.squeeze(sample[1]))\n",
    "    \n",
    "    main_res.extend(result)\n",
    "    \n",
    "target_samples = np.array(target_samples)\n",
    "contrastive_labels = tf.zeros(target_samples.shape[0]) # batch size \n",
    "\n",
    "unique_batch_values = np.unique(target_samples, axis=0)\n",
    "\n",
    "for i in range(unique_batch_values.shape[0]):\n",
    "\n",
    "    eq = tf.equal(unique_batch_values[i], target_samples)\n",
    "    \n",
    "    new_labels = tf.math.reduce_all(eq, axis=-1)\n",
    "    contrastive_labels = tf.where(new_labels, i, contrastive_labels)\n",
    "\n",
    "\n",
    "main_labels = np.array(contrastive_labels)\n",
    "main_res = np.array(main_res)\n",
    "\n",
    "print(main_res.shape)\n",
    "print(main_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee77511a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "pca = PCA(n_components=2)\n",
    "tsne = TSNE(n_components=2, learning_rate='auto', init='random', verbose=True, perplexity=30)\n",
    "\n",
    "print(main_res)\n",
    "\n",
    "result = pca.fit_transform(main_res)\n",
    "result = tsne.fit_transform(main_res)\n",
    "\n",
    "def res(x, label):\n",
    "    \n",
    "    uni = np.unique(label)\n",
    "    for u in uni:\n",
    "        \n",
    "        lu = label[label==u]\n",
    "        xu = x[label==u]\n",
    "        \n",
    "        rgb = np.random.rand(3,)\n",
    "        plt.scatter(xu[:,0], xu[:,1], color=[rgb])\n",
    "        \n",
    "        plt.show()\n",
    "    \n",
    "res(result, main_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "norman-bench",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_filename = \"checkpoints\\\\ckpt_\"+str(int(time.time()))\n",
    "if False:\n",
    "    model.encoder.save(save_filename+\"\\\\encoder_high_acc.h5\")\n",
    "    print(save_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1b0315",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
